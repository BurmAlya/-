Задание 19. Колония муравьёв для задачи о рюкзаке
Условие. Решить задачу о рюкзаке (0‑1) с помощью алгоритма муравьиной колонии (ACO):
построить маршруты «муравьёв» как наборы предметов, максимизируя ценность при
ограничении по весу.
Алгоритм: ACO с феромонами на рёбрах «предмет → предмет» и правилом выбора предмета
по удельной ценности и феромону.
Язык примера: Python
def aco_knapsack(weights, values, W, n_ants, n_iter):
 n = len(weights)
 # Феромоны: матрица n×n, начальное значение 1.0
 pheromone = [[1.0 for _ in range(n)] for _ in range(n)]
 best_value = 0
 best_items = []
 for iter in range(n_iter):
 all_solutions = []
 for ant in range(n_ants):
 solution = []
 total_weight = 0
 # Строим решение муравья: выбираем предметы по правилу ACO
 while True:
 # ДОПИСАТЬ: собрать список допустимых предметов (weight + total_weight ≤ W)
 # ДОПИСАТЬ: вычислить вероятности выбора по феромону и удельной ценности
 # ДОПИСАТЬ: выбрать предмет стохастически, добавить в solution
 all_solutions.append((solution, sum(values[i] for i in solution)))
 # Обновляем феромоны и лучший результат
 # ДОПИСАТЬ: испарить феромоны (умножить на коэффициент)
 # ДОПИСАТЬ: усилить феромоны на рёбрах лучших решений
 # Обновить best_value и best_items, если найдено лучшее
 return best_items, best_value
Что дописать:
Цикл поиска допустимых предметов.
Расчёт вероятностей выбора (с учётом феромона и weighti/valuei).
Стохастический выбор предмета (например, по методу рулетки).
Правила обновления феромонов (испарение и усиление).

                                     
                                     
                                     
Пошаговое описание работы алгоритма:
Создаётся матрица феромонов размером n×n (где n — число предметов), все значения = 1.0.
Устанавливаются начальные значения лучшего решения: best_value = 0, best_items = [].
Задаются параметры алгоритма:
rho = 0.1 — коэффициент испарения феромонов;
alpha = 1.0 — вес феромона в вероятностях;
beta = 2.0 — вес удельной ценности (value/weight).
Основной цикл (по итерациям)
Для каждой итерации:
Фаза построения решений (для каждого муравья):
Инициализируется пустое решение solution и нулевой вес total_weight.
В цикле:
Собирается список допустимых предметов (ещё не выбраны и не превышают вместимость рюкзака).
Если допустимых предметов нет — построение завершается.
Для каждого допустимого предмета вычисляется вероятность выбора, учитывающая:
уровень феромона на ребре (pheromone[len(solution)][i]);
удельную ценность предмета (values[i] / weights[i]).
Вероятности нормализуются (сумма = 1). Если все вероятности нулевые — выбор случайный.
Предмет выбирается стохастически (метод рулетки) и добавляется в решение.
Сохраняется решение и его ценность в all_solutions.
Фаза обновления феромонов:
Испарение: все значения матрицы феромонов умножаются на (1 − rho).
Усиление: для лучших решений текущей итерации увеличивается феромон на пройденных рёбрах (позиция в решении → выбранный предмет).
Обновление глобального лучшего решения: если лучшее решение текущей итерации лучше предыдущего, обновляются best_value и best_items.
Возврат результата
Возвращаются:
best_items — индексы выбранных предметов;
best_value — их суммарная ценность.

1. Инициализация параметров и данных
n = len(weights)  # количество предметов
pheromone = [[1.0 for _ in range(n)] for _ in range(n)]  # матрица феромонов
best_value = 0
best_items = []
rho = 0.1    # коэффициент испарения
alpha = 1.0  # вес феромона
beta = 2.0   # вес удельной ценности
2. Основной цикл по итерациям
for iter in range(n_iter):
    all_solutions = []  # все решения этой итерации
3. Цикл по муравьям (построение решений)

    for ant in range(n_ants):
        solution = []           # текущее решение муравья
        total_weight = 0       # текущий вес рюкзака
4. Построение решения для одного муравья
Шаг 4.1. Поиск допустимых предметов
        while True:
            allowed = []
            for i in range(n):
                if i not in solution and (total_weight + weights[i] <= W):
                    allowed.append(i)
            if not allowed:  # нет допустимых предметов
                break
Шаг 4.2. Расчёт вероятностей выбора
            probabilities = []
            total_prob = 0.0
            for i in allowed:
                value_per_weight = values[i] / weights[i]
                prob = (pheromone[len(solution)][i] ** alpha) * (value_per_weight ** beta)
                probabilities.append(prob)
                total_prob += prob
Шаг 4.3. Нормализация вероятностей
            if total_prob > 0:
                probabilities = [p / total_prob for p in probabilities]
            else:
                probabilities = [1.0 / len(allowed) for _ in allowed]
Шаг 4.4. Стохастический выбор предмета

            choice = random.choices(allowed, weights=probabilities)[0]
            solution.append(choice)
            total_weight += weights[choice]
5. Сохранение решения муравья
        solution_value = sum(values[i] for i in solution)
        all_solutions.append((solution, solution_value))
6. Обновление феромонов

Шаг 6.1. Испарение феромонов
    for i in range(n):
        for j in range(n):
            pheromone[i][j] *= (1 - rho)
Шаг 6.2. Поиск лучших решений итерации
    current_best_value = max(sol[1] for sol in all_solutions)
    current_best_solutions = [sol[0] for sol in all_solutions if sol[1] == current_best_value]
Шаг 6.3. Усиление феромонов на лучших путях
    for solution in current_best_solutions:
        for pos, item in enumerate(solution):
            pheromone[pos][item] += current_best_value / len(current_best_solutions)
7. Обновление глобального лучшего решения
    if current_best_value > best_value:
        best_value = current_best_value
        best_items = current_best_solutions[0]  # берём первое из лучших
8. Возврат результата
return best_items, best_value

Краткое описание шагов
Инициализация — задаём начальные значения феромонов и параметров алгоритма.
Основной цикл — повторяем заданное число итераций (n_iter).
Цикл по муравьям — каждый муравей строит своё решение.
Построение решения — муравей последовательно выбирает предметы:
находит допустимые предметы (не выбраны и не переполняют рюкзак);
рассчитывает вероятности выбора с учётом феромонов и ценности;
выбирает предмет стохастически.
Сохранение решений — все построенные решения сохраняются.
Обновление феромонов — сначала испарение, затем усиление на лучших путях.
Обновление лучшего решения — если найдено лучшее решение, обновляем глобальный рекорд.
Возврат результата — возвращаем лучший найденный набор предметов и его ценность.
Временная сложность алгоритма 
Итоговая оценка:  
O(n_iter *n_ants* n^2 + n_iter* n^2) = O(n_iter* n_ants*n^2),  
где:  
- n — количество предметов,  
- n_ants — число муравьёв,  
- n_{iter — число итераций.
Поэтапный разбор сложности

1. Инициализация 
- Создание матрицы феромонов: O(n^2) 
- Остальные операции (присваивания) — O(1).  
→ Суммарно: O(n^2).

2. Основной цикл по итерациям**  
Выполняется n_iter раз.

3. Цикл по муравьям  
Выполняется n_ants раз за каждую итерацию.

4. Построение решения для одного муравья  
- Поиск допустимых предметов (`allowed`):  
  - Цикл по всем n предметам.  
  - Проверка: O(1) на предмет.  
  → Сложность: O(n).  


- Расчёт вероятностей выбора:  
  - Цикл по списку `allowed` (в худшем случае O(n) предметов).  
  - Для каждого предмета: вычисление удельной ценности и вероятности — O(1).  
  → Сложность: O(n).  

- Нормализация вероятностей:  
  - Проход по списку `probabilities` (O(n) элементов).  
  → Сложность: O(n).  


-Стохастический выбор предмета (`random.choices`):  
  - В худшем случае требует $O(n)$ операций (зависит от реализации).  
  → Сложность: O(n).  


- Повторение цикла построения решения:  
  - Муравей может выбрать до n предметов.  
  - На каждом шаге:$O(n) операций.  
  → Общая сложность построения одного решения: O(n^2).  


→ Сложность для всех муравьёв за итерацию: 
n_ants *O(n^2) = O(n_ants *n^2).


5. Обновление феромонов  
- Испарение:  
  - Двойной цикл по матрице n * n.  
  → Сложность: O(n^2).  


- Усиление феромонов:  
  - Цикл по лучшим решениям текущей итерации (в худшем случае O(n_ants) решений).  
  - Для каждого решения: проход по его предметам (O(n)).  
  →Сложность:O(n_ants * n).  

  - Но так как n_ants << n на практике, доминирует O(n^2) из‑за испарения.


→ Общая сложность обновления феромонов за итерацию: O(n^2).


6. Обновление глобального лучшего решения 
- Поиск максимума в списке решений: O(n_ants).  
- Копирование лучшего решения: O(n).  
→Сложность:O(n_ants + n) = O(n_ants) (так как n_ants > n обычно).


Описание временной сложности
Итоговая агрегация
1. За одну итерацию  
   - Построение решений: O(n_ants * (n^2).  
   - Обновление феромонов: O(n^2).  
   → Суммарно за итерацию: O(n_ants * n^2 + n^2) = O(n_ants * n^2).
2. За все итерации (n_iter):  
   O(n_iter*(n_ants * n^2)) = O(n_iter *n_ants * n^2).
Почему такая сложность
- Квадратичная зависимость от n возникает из‑за:  
  - Матрицы феромонов (n * n).  
  - Поиска допустимых предметов и расчёта вероятностей на каждом шаге построения решения.  
- Линейная зависимость от n_ants — каждый муравей независимо строит решение.  
- Линейная зависимость от n_iter — алгоритм повторяет процесс оптимизации заданное число раз.
Практические замечания
- Худший случай: O(niter * n_ants * n^2).  
- Лучший случай(редкий): если муравьи быстро находят оптимальное решение, число итераций может сократиться, но асимптотика остаётся той же.  
- Оптимизации возможны, но не меняют асимптотику:  
  - Кэширование степеней вершин.  
  - Ранняя остановка при стабилизации результата.
Описание временной сложности алгоритма ACO для задачи о рюкзаке
Итоговая сложность:  
**$O(n_{\text{iter}} \cdot n_{\text{ants}} \cdot n^2)$**,  
где:  
- $n$ — количество предметов,  
- $n_{\text{ants}}$ — число муравьёв,  
- $n_{\text{iter}}$ — число итераций
 Что означает эта сложность
1. **Кубический характер относительно входных параметров**  
   - Алгоритм масштабируется **нелинейно** с ростом:
     - числа предметов ($n^2$),  
     - числа муравьёв ($n_{\text{ants}}$),  
     - числа итераций ($n_{\text{iter}}$).  
   - Это означает, что при удвоении $n$ время работы вырастет примерно в **4 раза**; при удвоении $n_{\text{ants}}$ или $n_{\text{iter}}$ — в **2 раза**.

2. **Доминирующий множитель — $n^2$**  
   - Основная «тяжесть» приходится на:
     - перебор предметов при построении решений,  
     - обновление матрицы феромонов ($n \times n$).  
   - Даже при малых $n_{\text{ants}}$ и $n_{\text{iter}}$ рост $n$ резко увеличивает время.


3. **Линейная зависимость от $n_{\text{ants}}$**  
   - Каждый муравей независимо строит решение.  
   - Увеличение числа муравьёв прямо пропорционально увеличивает нагрузку.  
   - На практике $n_{\text{ants}}$ выбирают небольшим (10–50), чтобы не «раздувать» время.

4. **Линейная зависимость от $n_{\text{iter}}$**  
   - Каждая итерация повторяет полный цикл: построение решений + обновление феромонов.  
   - Больше итераций → точнее результат, но дольше работа.  
   - На практике используют 50–500 итераций.
 Почему именно такая сложность?
1. **Построение решений ($O(n_{\text{ants}} \cdot n^2)$ на итерацию)**  
   - Каждый муравей может выбрать до $n$ предметов.  
   - На каждом шаге:  
     - поиск допустимых предметов — $O(n)$,  
     - расчёт вероятностей — $O(n)$,  
     - выбор предмета — $O(n)$.  
   - Итого на одного муравья: $O(n^2)$.  
   - На всех муравьёв: $O(n_{\text{ants}} \cdot n^2)$.
2. Обовление феромонов ($O(n^2)$ на итерацию)  
   - Испарение: двойной цикл по матрице $n \times n$ → $O(n^2)$.  
   - Усиление: в худшем случае обход всех решений и их предметов → $O(n_{\text{ants}} \cdot n)$, но обычно $n_{\text{ants}} \ll n$, поэтому доминирует $O(n^2)$.
3. Повторение $n_{\text{iter}}$ раз  
   - Каждый цикл (построение + обновление) выполняется $n_{\text{iter}}$ раз.  
   - Итоговая сложность: $O(n_{\text{iter}} \cdot (n_{\text{ants}} \cdot n^2 + n^2)) = O(n_{\text{iter}} \cdot n_{\text{ants}} \cdot n^2)$.
 Ограничения и пути оптимизации
Проблемы:  
- Непригоден для очень больших n (тысячи предметов) из‑за $O(n^2)$.  
- Чувствительность к параметрам ($n_{\text{ants}}$, $n_{\text{iter}}$): неверный выбор → долгий расчёт или плохой результат.  
- Стохастичность разные запуски могут давать разный результат.
Возможные оптимизации  
1. Ограничение списка допустимых предметов  
   - Предварительная фильтрация (например, по удельной ценности).  
   - Снижение средней длины `allowed` с $O(n)$ до $O(\sqrt{n})$.  
2. Аппроксимация матрицы феромонов  
   - Хранение только значимых рёбер (разреженная матрица).  
3. Ранняя остановка
   - Если лучшее решение не улучшается $k$ итераций — прерываем.  
4. Параллелизация  
   - Расчёт решений муравьёв в отдельных потоках.  
5. Кэширование степеней вершин  
   - Пересчёт степеней только при изменении `deleted`.                      
  Итог
- Сложность $O(n_{\text{iter}} \cdot n_{\text{ants}} \cdot n^2)$ отражает:  
  - квадратичный рост с числом предметов,  
  - линейную зависимость от числа муравьёв и итераций.  
- Практическое применение  
  - хорошо для $n \leq 100$,  
  - требует оптимизаций для $n > 100$.  
- **Ключевой вывод**: алгоритм балансирует точность и скорость, но не подходит для сверхбольших задач без модификаций.


ОТВЕТ НА КОНТРОЛЬНЫЙ ВОПРОС ноемр 19
Компромисс между точностью и скоростью в приближённых алгоритмах заключается в следующем
Чем выше требуемая точность — тем больше вариантов решений нужно проанализировать, тем **дольше работает алгоритм**.
Чем важнее скорость — тем сильнее приходится упрощать вычисления, тем **ниже гарантированная точность результата**.
Суть компромисса
- Точные алгоритмы гарантируют оптимальное решение, но часто работают слишком медленно (экспоненциальное время) на больших данных.
- Приближённые алгоритмы сознательно жертвуют точностью ради скорости: дают «достаточно хорошее» решение за приемлемое время (обычно полиномиальное).
Примеры
- Задача коммивояжёра точный перебор — $O(n!)$ (неприемлемо для $n>15$), 2‑opt‑эвристика — $O(n^2)$ (быстро, но маршрут на 5–15 % длиннее оптимального).
- Задача о рюкзаке динамическое программирование — $O(n·W)$ (медленно при большой вместимости $W$), жадный алгоритм — O(n \log n) (быстро, но ценность на 20–30 % ниже).
 Как управляют компромиссом
1. Настройка параметров (больше итераций → выше точность, но дольше).
2. Гибридные схемы (приближённый метод + локальная оптимизация).
3. Ранняя остановка (прервать, если улучшения малы).
4. Оценка погрешности (сравнение с границами оптимального решения)
Итог: выбор между точностью и скоростью зависит от задачи:  
- критична точность → точные методы;  
- критично время → приближённые методы.











                                     
